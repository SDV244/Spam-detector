name: Train Spam Detector

on:
  push:
    branches:
      - main
  workflow_dispatch:

jobs:
  train:
    runs-on: ubuntu-latest
    
    services:
      mlflow-server:
        image: ghcr.io/mlflow/mlflow
        ports:
          - 5000:5000
        env:
          MLFLOW_ARTIFACT_ROOT: ./mlruns
          MLFLOW_BACKEND_STORE_URI: sqlite:///mlflow.db
        options: >-
          --health-cmd "curl -f http://localhost:5000" 
          --health-interval 10s 
          --health-timeout 5s 
          --health-retries 5

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.10"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Create directories
        run: |
          mkdir -p mlruns
          touch mlflow.db

      - name: Run training script
        run: |
          python train.py
        env:
          MLFLOW_TRACKING_URI: http://localhost:5000

      - name: Verify artifacts exist
        run: |
          ls -la
          ls -la mlruns/
          test -f spam_model.joblib || echo "spam_model.joblib not found!"
          test -f training_data.csv || echo "training_data.csv not found!"

      - name: Archive and upload results
        run: |
          # Solo empaquetar archivos que existan
          tar -czvf mlruns.tar.gz mlruns/
          
          FILES_TO_TAR="requirements.txt"
          [ -f spam_model.joblib ] && FILES_TO_TAR="$FILES_TO_TAR spam_model.joblib"
          [ -f training_data.csv ] && FILES_TO_TAR="$FILES_TO_TAR training_data.csv"
          
          tar -czvf model_artifacts.tar.gz $FILES_TO_TAR

      - name: Upload artifacts
        uses: actions/upload-artifact@v4
        with:
          name: training-results
          path: |
            mlruns.tar.gz
            model_artifacts.tar.gz
          retention-days: 7
